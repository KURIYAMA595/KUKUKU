{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2bc208-f760-4670-be5e-af862cb7e467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== 分类评估报告 ==========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        普通邮件       0.50      0.50      0.50         2\n",
      "        垃圾邮件       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.58      0.58      0.58         5\n",
      "weighted avg       0.60      0.60      0.60         5\n",
      "\n",
      "\n",
      "========== 邮件分类结果 ==========\n",
      "邮件_files/151.txt 分类情况: 垃圾邮件\n",
      "邮件_files/152.txt 分类情况: 垃圾邮件\n",
      "邮件_files/153.txt 分类情况: 普通邮件\n",
      "邮件_files/154.txt 分类情况: 垃圾邮件\n",
      "邮件_files/155.txt 分类情况: 普通邮件\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\11aaa111zhuanye\\p\\conda\\envs\\nlp_kuriyama\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from jieba import cut\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from imblearn.over_sampling import SMOTE  # 新增SMOTE\n",
    "from sklearn.metrics import classification_report  # 新增评估报告\n",
    "\n",
    "def get_words(filename):\n",
    "    \"\"\"读取文本并过滤无效字符和长度为1的词\"\"\"\n",
    "    words = []\n",
    "    with open(filename, 'r', encoding='utf-8') as fr:\n",
    "        for line in fr:\n",
    "            line = line.strip()\n",
    "            line = re.sub(r'[.【】0-9、——。，！~\\*]', '', line)\n",
    "            line = cut(line)\n",
    "            line = filter(lambda word: len(word) > 1, line)\n",
    "            words.extend(line)\n",
    "    return words\n",
    "\n",
    "all_words = []\n",
    "\n",
    "def get_top_words(top_num):\n",
    "    \"\"\"获取高频词\"\"\"\n",
    "    filename_list = [f'邮件_files/{i}.txt' for i in range(151)]\n",
    "    for filename in filename_list:\n",
    "        all_words.append(get_words(filename))\n",
    "    freq = Counter(chain(*all_words))\n",
    "    return [i[0] for i in freq.most_common(top_num)]\n",
    "\n",
    "def main():\n",
    "    # 1. 数据准备\n",
    "    train_files = [f'邮件_files/{i}.txt' for i in range(151)]\n",
    "    test_files = [f'邮件_files/{i}.txt' for i in range(151, 156)]\n",
    "    \n",
    "    # 2. 特征工程\n",
    "    top_words = get_top_words(100)\n",
    "    \n",
    "    # 构建训练特征\n",
    "    vector = []\n",
    "    for words in all_words:\n",
    "        word_map = list(map(lambda word: words.count(word), top_words))\n",
    "        vector.append(word_map)\n",
    "    X_train = np.array(vector)\n",
    "    y_train = np.array([1]*127 + [0]*24)  # 原始标签\n",
    "    \n",
    "    # 3. 样本平衡处理（新增核心代码）\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # 4. 模型训练\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_res, y_res)\n",
    "    \n",
    "    # 5. 构建测试特征\n",
    "    X_test = []\n",
    "    for file in test_files:\n",
    "        words = get_words(file)\n",
    "        word_map = list(map(lambda word: words.count(word), top_words))\n",
    "        X_test.append(word_map)\n",
    "    X_test = np.array(X_test)\n",
    "    \n",
    "    # 假设测试集的真实标签（需要根据实际情况修改）\n",
    "    y_test = np.array([1, 1, 0, 0, 1])  # 示例标签\n",
    "    \n",
    "    # 6. 预测与评估（新增核心代码）\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"\\n========== 分类评估报告 ==========\")\n",
    "    print(classification_report(y_test, y_pred, \n",
    "                               target_names=[\"普通邮件\", \"垃圾邮件\"]))\n",
    "    \n",
    "    # 7. 输出预测结果\n",
    "    print(\"\\n========== 邮件分类结果 ==========\")\n",
    "    for i, file in enumerate(test_files):\n",
    "        result = \"垃圾邮件\" if y_pred[i] == 1 else \"普通邮件\"\n",
    "        print(f\"{file} 分类情况: {result}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
